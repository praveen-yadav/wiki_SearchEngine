{{other uses|Multitasking (disambiguation)}}
{{refimprove|date=February 2012}}
[[File:Screenshot of Debian (Release 7.1, "Wheezy") running the GNOME desktop environment, Firefox, Tor, and VLC Player.jpg|thumb|right|350px|Modern desktop [[operating systems]] have to handle [[executable file|executing]] large numbers of different [[process (computing)|processes]] simultaneously. Here is a screenshot of [[Debian Linux]] (version 7.1, "Wheezy") running the [[GNOME]] [[desktop environment]], [[Firefox]], [[Tor (anonymity network)|Tor]], and [[VLC media player]], all at the same time.]]

In computing, '''multitasking''' is a method where multiple  [[Task (computers)|task]]s, also known as [[Computer process|processes]], are performed during the same period of time. The tasks share common processing resources, such as a [[Central processing unit|CPU]] and main memory.

In the case of a computer with a single CPU, only one task is said to be ''running'' at any point in time, meaning that the CPU is actively executing instructions for that task. Multitasking solves the problem by [[Scheduling (computing)|scheduling]] which task may be the one running at any given time, and when another waiting task gets a turn.  The act of reassigning a CPU from one task to another one is called a [[context switch]]. When context switches occur frequently enough the illusion of [[Parallel computing|parallelism]] is achieved.

Even on computers with more than one CPU (called [[multiprocessor]] machines), multitasking allows many more tasks to be run than there are CPUs. The term "multitasking" has become an international term, as the same word is used in many other languages such as German, Italian, Dutch, Danish and Norwegian.

Operating systems may adopt one of many different [[Scheduling (computing)|scheduling strategies]], which generally fall into the following categories{{cn|date=July 2013}}:
* In ''[[multiprogramming]]'' systems, the running task keeps running until it performs an operation that requires waiting for an external event (e.g. reading from a tape) or until the computer's scheduler forcibly swaps the running task out of the CPU. Multiprogramming systems are designed to maximize CPU usage.
* In ''[[time-sharing]]'' systems, the running task is required to relinquish the CPU, either voluntarily or by an external event such as a [[hardware interrupt]]. Time sharing systems are designed to allow several programs to execute apparently simultaneously.
* In ''[[Real-time computing|real-time]]'' systems, some waiting tasks are guaranteed to be given the CPU when an external event occurs. Real time systems are designed to control mechanical devices such as industrial robots, which require timely processing.

== Multiprogramming ==
In the early days of computing, [[CPU time]] was expensive, and [[peripheral]]s were very slow. When the computer ran a program that needed access to a peripheral, the Central processing unit (CPU) would have to stop executing program instructions while the peripheral processed the data. This was deemed very inefficient.{{cn|date=July 2013}}

The first computer using a multiprogramming system was the British ''[[LEO (computer)#Applications and successors|Leo III]]'' owned by [[J. Lyons and Co.]]. Several different programs in batch were loaded in the computer memory, and the first one began to run. When the first program reached an instruction waiting for a peripheral, the context of this program was stored away, and the second program in memory was given a chance to run. The process continued until all programs finished running.{{cn|date=July 2013}}

The use of multiprogramming was enhanced by the arrival of [[virtual memory]] and [[virtual machine]] technology, which enabled individual programs to make use of memory and operating system resources as if other concurrently running programs were, for all practical purposes, non-existent and invisible to them.{{cn|date=July 2013}}

Multiprogramming doesn't give any guarantee that a program will run in a timely manner. Indeed, the very first program may very well run for hours without needing access to a peripheral. As there were no users waiting at an interactive terminal, this was no problem: users handed in a deck of punched cards to an operator, and came back a few hours later for printed results. Multiprogramming greatly reduced wait times when multiple batches were being processed.{{cn|date=July 2013}}

== Cooperative multitasking/time-sharing ==<!-- This section is linked from [[Apple IIGS]] -->
{{see also|Nonpreemptive multitasking}}
The expression 'time sharing' was usually used to designate computers shared by interactive users at terminals, such as IBM's [[Time Sharing Option|TSO]], and [[CP/CMS|VM/CMS]]. The term ''time-sharing'' is no longer commonly used, having been replaced by simply ''multitasking'', and by the advent of personal computers and workstations rather than shared interactive systems.
When computer usage evolved from batch mode to interactive mode, multiprogramming was no longer a suitable approach. Each user wanted to see his program running as if it were the only program in the computer. The use of time sharing made this possible, with the qualification that the computer would not seem as fast to any one user as it really would be if it were running only that user's program.{{cn|date=July 2013}}

Early multitasking systems used applications that voluntarily ceded time to one another. This approach, which was eventually supported by many computer [[operating system]]s, is known today as cooperative multitasking. Although it is now rarely used in larger systems, cooperative multitasking was once the scheduling scheme employed by [[Microsoft Windows]] (prior to [[Windows 95]] and [[Windows NT]]) and [[Mac OS]] (prior to [[Mac OS X]]) in order to enable multiple applications to be run simultaneously. [[Windows 9x]] also used cooperative multitasking, but only for 16-bit legacy applications, much the same way as pre-[[Mac OS X v10.5|Leopard]] [[PowerPC]] versions of Mac OS X used it for [[Classic (Mac OS X)|Classic]] applications. The network operating system [[NetWare]] used cooperative multitasking up to NetWare 6.5. Cooperative multitasking is still used today on [[RISC OS]] systems.{{cn|date=July 2013}}

Because a cooperatively multitasked system relies on each process regularly giving up time to other processes on the system, one poorly designed program can consume all of the CPU time for itself or cause the whole system to [[hang (computing)|hang]]. In a server environment, this is a hazard that makes the entire network brittle and fragile. All software must be evaluated and cleared for use in a test environment before being installed on the main server, or a misbehaving program on the server slows down or freezes the entire network.{{cn|date=July 2013}}

Despite the difficulty of designing and implementing cooperatively multitasked systems, time-constrained, real-time embedded systems (such as spacecraft) are often implemented using this paradigm. This allows highly reliable, deterministic control of complex real time sequences, for instance, the firing of thrusters for deep space course corrections.{{cn|date=July 2013}}

== Preemptive multitasking/time-sharing ==
{{Main|Preemption (computing)}}

Preemptive multitasking allows the computer system to guarantee more reliably each process a regular "slice" of operating time. It also allows the system to deal rapidly with important external events like incoming data, which might require the immediate attention of one or another process.{{cn|date=July 2013}}

Operating systems were developed to take advantage of these hardware capabilities and run multiple processes preemptively. Digital Equipment Corporation was a leader in this. For example, preemptive multitasking was implemented in the earliest version of [[Unix]] <ref>{{cite web|url=http://www.ibiblio.org/team/intro/unix/what.html |title=But Unix was far later than Digital. The Digital Research Initiative |publisher=Ibiblio.org |date= |accessdate=2013-09-08}}</ref> in 1969, and is standard in Unix and [[Unix-like]] operating systems, including [[Linux]], [[Solaris (operating system)|Solaris]] and [[Berkeley Software Distribution|BSD]] with its [[Comparison of BSD operating systems|derivatives]].

At any specific time, processes can be grouped into two categories: those that are waiting for input or output (called "[[I/O bound]]"), and those that are fully utilizing the CPU ("[[CPU bound]]"). In primitive systems, the software would often "[[Polling (computer science)|poll]]", or "[[Busy waiting|busywait]]" while waiting for requested input (such as disk, keyboard or network input). During this time, the system was not performing useful work. With the advent of interrupts and preemptive multitasking, I/O bound processes could be "blocked", or put on hold, pending the arrival of the necessary data, allowing other processes to utilize the CPU. As the arrival of the requested data would generate an interrupt, blocked processes could be guaranteed a timely return to execution.{{cn|date=July 2013}}

The earliest preemptive multitasking OS available to home users was [[Sinclair QDOS]] on the [[Sinclair QL]], released in 1984, but very few people bought the machine. Commodore's powerful [[Amiga]], released the following year, was the first commercially successful home computer to use the technology, and its multimedia abilities make it a clear ancestor of contemporary multitasking personal computers. [[Microsoft]] made preemptive multitasking a core feature of their flagship operating system in the early 1990s when developing [[Windows NT 3.1]] and then [[Windows 95]]. It was later adopted on the Apple Macintosh by [[Mac OS]] 9.x <ref>{{cite web|url=http://developer.apple.com/technotes/tn/tn2006.html |title=Technical Note TN2006: MP-Safe Routines |publisher=Developer.apple.com |date= |accessdate=2013-09-08}}</ref> as an additional API, i.e. the application could be programmed to use the preemptive or cooperative model, and all legacy applications were multitasked cooperatively within a single process. [[Mac OS X]], being a [[Unix-like]] system, uses preemptive multitasking for all native applications, although [[Classic (Mac OS X)|Classic]] applications are multitasked cooperatively in a Mac OS 9 environment that itself is running as an OS X process (and is subject to preemption like any other OS X process).

A similar model is used in [[Windows 9x]] and the [[Windows NT|Windows NT family]], where native 32-bit applications are multitasked preemptively, and legacy 16-bit [[Windows 3.1x|Windows 3.x]] programs are multitasked cooperatively within a single process, although in the NT family it is possible to force a 16-bit application to run as a separate preemptively multitasked process.<ref>[http://www.smartcomputing.com/editorial/article.asp?article=articles%2F2005%2Fs1606%2F08s06%2F08s06.asp Smart Computing Article - Windows 2000 &16-Bit Applications]{{dead link|date=September 2013}}</ref> 64-bit editions of Windows, both for the [[x86-64]] and [[Itanium]] architectures, no longer provide support for legacy 16-bit applications, and thus provide preemptive multitasking for all supported applications.

== Real time ==
Another reason for multitasking was in the design of [[real-time computing]] systems, where there are a number of possibly unrelated external activities needed to be controlled by a single processor system. In such systems a hierarchical interrupt system is coupled with process prioritization to ensure that key activities were given a greater share of available [[process time]].{{cn|date=July 2013}}

== Multithreading ==
As multitasking greatly improved the throughput of computers, programmers started to implement applications as sets of cooperating processes (e.&nbsp;g., one process gathering input data, one process processing input data, one process writing out results on disk). This, however, required some tools to allow processes to efficiently exchange data.{{cn|date=July 2013}}

[[Thread (computer science)|Threads]] were born from the idea that the most efficient way for cooperating processes to exchange data would be to share their entire memory space. Thus, threads are basically processes that run in the same memory context. Threads are described as ''lightweight'' because switching between threads does not involve changing the memory context.{{cn|date=July 2013}}

While threads are scheduled preemptively, some operating systems provide a variant to threads, named ''[[Fiber (computer science)|fiber]]s'', that are scheduled cooperatively. On operating systems that do not provide fibers, an application may implement its own fibers using repeated calls to worker functions. Fibers are even more lightweight than threads, and somewhat easier to program with, although they tend to lose some or all of the benefits of threads on [[multiprocessing|machines with multiple processors]].{{Citation needed|date=August 2007}}

Some systems directly support [[Multithreading (computer hardware)|multithreading in hardware]].

== Memory protection ==
{{Main|Memory protection}}

When multiple programs are present in memory, an ill-behaved program may (inadvertently or deliberately) overwrite memory belonging to another program, or even to the operating system itself.{{cn|date=July 2013}}

The operating system therefore restricts the memory accessible to the running program. A program trying to access memory outside its allowed range is immediately stopped before it can change memory belonging to another process.{{cn|date=July 2013}}

Another key innovation was the idea of privilege levels. Low privilege tasks are not allowed some kinds of memory access and are not allowed to perform certain instructions. When a task tries to perform a privileged operation a [[Trap (computing)|trap]] occurs and a supervisory program running at a higher level is allowed to decide how to respond.{{cn|date=July 2013}}

== Memory swapping ==
Use of a [[Virtual memory|swap file]] or swap partition is a way for the operating system to provide more memory than is physically available by keeping portions of the primary memory in [[secondary storage]]. While multitasking and memory swapping are two completely unrelated techniques, they are very often used together, as swapping memory allows more tasks to be loaded at the same time.  Typically, a multitasking system allows another process to run when the running process hits a point where it has to wait for some portion of memory to be reloaded from secondary storage.{{cn|date=July 2013}}

== Programming in a multitasking environment ==
Processes that are entirely independent are not much trouble to program. Most of the complexity in multitasking systems comes from the need to share computer resources between tasks and to synchronize the operation of co-operating tasks.{{cn|date=July 2013}}

Various [[concurrent computing]] techniques are used to avoid potential problems caused by multiple tasks attempting to access the same resource.{{cn|date=July 2013}}

Bigger systems were sometimes built with a central processor(s) and some number of [[Channel I/O|I/O processors]], a kind of asymmetric [[multiprocessing]].{{cn|date=July 2013}}

Over the years, multitasking systems have been refined. Modern operating systems generally include detailed mechanisms for prioritizing processes, while [[symmetric multiprocessing]] has introduced new complexities and capabilities.{{cn|date=July 2013}}

== See also ==
* [[Process state]]

== Notes ==
{{Reflist}}
{{Operating System}}
{{Parallel computing}}

{{DEFAULTSORT:Computer Multitasking}}
[[Category:Concurrent computing]]
[[Category:Operating system technology]]